## Problem Solving

### What is a Problem?

A problem can be broken down into these components:

* Initial state (e.g. the agent being in a given city)
* Actions(s) is a set of possible actions when the agent is in a given state, not necessarily dependant on the state.
* Result(s,a) -> s' is the new state after the agent performed a given action
* GoalTest(s) -> T|F telling whether the state is the goal or not
* PathCost(s->s->s) -> n which takes a set of states and actions and returns its cost
    * StepCost(s,a,s') -> n which is the cost of a single step/action

### Parts of a state

* Frontier: the ends of the paths (furthest explored part)
* Explored region
* Unexplored region

### Tree Search

	function tree_search(problem)
	frontier = { [initial] }
	   loop:
	      if frontier is empty: return FAIL
	      path = remove_choice(frontier)
	      s = path.end
	      if goal_test(s): return path
	      for a in actions:
	         add [path + a -> Result(s,a)] to frontier

Cons: doesn't keep track of explored states and may go back to previously visited state

### Graph Search

	function graph_search(problem)
	frontier = { [initial] }
	explored = {}
	   loop:
	      if frontier is empty: return FAIL
	      path = remove_choice(frontier)
	      s = path.end
	      add s to explored
	      if goal_test(s): return path
	      for a in actions:
	         add [path + a -> Result(s,a)] to frontier unless Result(s,a) in frontier+explored

Keeping track of previously explored states and the frontier, the algorithm is capable of eliminating cycles.

### Breadth-First Search

It will choose the shortest length path (size-wise and not cost-wise) to be expanded first. It will try to look for all children of a given node before going further to their grandchildren.

### Uniform Cost Search (Cheapest First Search)

The algorithm will expand the node which contains the cheapest total cost first. It guarantees it is the cheapest path because that path will be expanded before more expensive ones.

It expands paths like a topological map, expanding paths up to a given distance, and then further.

It is expected to expand half of the space before getting to the goal. If the space is large, that could be time consuming.

### Depth-First Seach

It always expands the longest path first. It's 'the opposite' of the Breadth-First Search.

### Search Comparison

Breadth-First and Cheapest-First are both optimal algorithms in terms of shortest and cheapest paths, respectively (assuming the cost is always positive). Depth-First is not optimal in terms of shortest path.

Depth-First search, on the other hand, has a great advantage in terms of space, because when keeping track of the frontier, it will always contain _n_ states, while the other two will contain roughly 2^n states.

Both Breadth-First and Cheapest-First are complete. That is, if there is a solution, they are guaranteed to find it, even if the tree is infinite. The Depth-First search is not guaranteed in this case.

### Greedy Best-First Search

It uses an estimate of the distance towards the goal (e.g. the straigh line distance between the starting point and the goal) to guess what it should expand next. This is optimal if there are no obstacles.

However, it is not guaranteed to find the optimal solution if there are obstacles. 

	            \              ......
	S .........  \             G  / .
	           .  \              / .
	            .  ----         / .
	             ..... \-------/ .
	                  ...........


### A* Search

It always expands the path with minimum f function, where:

	f = g + h
	g(path) = path cost
	h(path) = h(s) = estimated distance to the goal

It could be called Best Estimated Total Cost First. The optimal solution will be found depending of the heuristic function h. This will happen when:

* h(s) < true cost
* h never overestimate
* h is optimistic
* h is admissable to be used to find the lowest cost path

### An optimistic h function finds the lowest cost path
	f = g + h
	h(s) < true cost(s -> G)
	
Since new paths are explored cheapest first, then all paths in and beyond the frontier (besides the goal) must have a cost greater than the cost of the goal. This is true for non-negative step costs.

### State Spaces

They don't need to be in 2D, like the road problem. For example, the vacuum robot problem can have a different state space:

* The number of positions for the robot to be (2)
* Each space may have dirt in it or not (2^2)
* Total number of states: 2x(2^2) = 8

If we add new constraints, the problem may be even more complicated:

* The robot has a camera that can be: on, off (2)
* The robot has a power switch that can be: on, off, sleep (3)
* The robot has a brush that has 5 heights (5)
* The number of positions for the robot to be (10)
* Each space may have dirt in it or not (2^10)
* Total number of states: 2x3x5x10x(2^10) = 307.200

### Automatic Heuristics

Coming up with the heuristics is the hardest part, but it can be done automatically by simply manipulating the formal rules of the problem. This is called **generating a relaxed problem**.

Example: In the sliding blocks puzzle, we can manipulate the formal rules to come up with heuristics.

	a block can move A -> B
	if (A adjacent to B)
	and (B is blank)

* _h1_: we cross out both rules and have the number of displaced blocks
* _h2_: we cross out the 2nd rule and have the distance to the correct place
* _h_: `max(h1, h2)` is admissible as long as _h1_ and _h2_ are admissible, but can take long to compute

This is like adding new operators, or adding new links in the state space, which will only make the problem easier and thus, never overestimating.

	o ---> o ---> o
	  \---------/

### Problem-solving works when the domain/environment is:

* **Fully observable**, i.e. we must be able to see the initial state we start out with.
* **Known**, i.e. the set of available actions must be known
* **Discrete**, i.e. finite number of actions
* **Deterministic**, i.e. the result of the action must be known
* **Static**, i.e. nothing changes the world besides our actions

### Implementation

For a given path `A ---> S ---> F`, we have three nodes. A _node_ can be represented as a data structure (linked list) with four fields:

* state: indicates the state at the end of the path (F)
* action: action to get there (SF)
* cost: total cost (n)
* parent: pointer to another node (S) that has a parent that points to another node (A) that has a null parent.

The _**frontier**_ has three operations: removing the best item and adding new ones and a membership test. A priority queue seems good because it knows how to keep track of best items in order. Building it from a hash table or a tree makes it possible to check for membership.

The _**explored**_ has two operations: add new members and check for membership. It can be represented as a set with a hash table or a tree.

